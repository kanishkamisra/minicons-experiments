{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f330f9e0",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"minicons: Enabling Flexible Behavioral and Representational Analyses of Transformer Language Models\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "author:\n",
    "  - name: Kanishka Misra\n",
    "    url: https://kanishka.website\n",
    "    affiliation: Purdue University\n",
    "date: 08-01-2022\n",
    "affiliation: Purdue University\n",
    "title-block-banner: \"#22577E\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e9a7f",
   "metadata": {},
   "source": [
    "<!-- ![logo](miniconslogo.png) -->\n",
    "<!-- <img src=\"miniconslogo.png\" alt=\"minicons\" style=\"width:150px;display: block; margin-left: auto; margin-right: auto;\"/> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba6eac",
   "metadata": {},
   "source": [
    "# Scorer Module\n",
    "\n",
    "The scorer module elicits conditional probabilities from stimuli, given any model trained using Huggingface `transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47c3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from minicons import scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d25609",
   "metadata": {},
   "source": [
    "## Model Instantiation\n",
    "\n",
    "minicons can use any model from Huggingface Transformers\n",
    "\n",
    "Here, we use GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7605167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "lm = scorer.IncrementalLMScorer('gpt2', 'cpu') # for GPU use cuda:<DEVICENAME>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90e54e6",
   "metadata": {},
   "source": [
    "## Demo: Grammatical Acceptability\n",
    "\n",
    "Sentences collected from BLiMP (Warstadt et al., 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee3e26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_sentences = [\n",
    "    'The keys to the cabinet are on the table.',\n",
    "    'The cats annoy Tim.',\n",
    "    \"Rose wasn't disturbing Mark.\",\n",
    "    'Carlos said that Lori helped him.'\n",
    "]\n",
    "\n",
    "unacceptable_sentences = [\n",
    "    'The keys to the cabinet is on the table.',\n",
    "    'The cats annoys Tim.',\n",
    "    \"Rose wasn't boasting Mark\",\n",
    "    'Carlos said that Lori helped himself.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd20221",
   "metadata": {},
   "source": [
    "### Batch-wise sentence log-probabilities per token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bd57772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The keys to the cabinet are on the table.', -5.607510089874268),\n",
       " ('The cats annoy Tim.', -12.293123245239258),\n",
       " (\"Rose wasn't disturbing Mark.\", -9.35051441192627),\n",
       " ('Carlos said that Lori helped him.', -8.524112701416016)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceptable_scores = lm.sequence_score(acceptable_sentences)\n",
    "unacceptable_scores = lm.sequence_score(unacceptable_sentences)\n",
    "\n",
    "list(zip(acceptable_sentences, acceptable_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4884c01",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "Percentage of time model scores acceptable greater than unacceptable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0d6446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model achieves an accuracy of 75.0%\n"
     ]
    }
   ],
   "source": [
    "comparisons = torch.tensor(acceptable_scores) > torch.tensor(unacceptable_scores)\n",
    "acc = comparisons.float().mean().item()\n",
    "\n",
    "print(f\"The model achieves an accuracy of {round(acc*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa8519",
   "metadata": {},
   "source": [
    "## Token-wise log-probabilities, in batched manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e50e568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 0.0),\n",
       "  ('keys', -9.825798034667969),\n",
       "  ('to', -0.9178085327148438),\n",
       "  ('the', -2.2056198120117188),\n",
       "  ('cabinet', -8.424751281738281),\n",
       "  ('is', -4.4639739990234375),\n",
       "  ('on', -5.424781799316406),\n",
       "  ('the', -0.416473388671875),\n",
       "  ('table', -4.647712707519531),\n",
       "  ('.', -1.681610107421875)],\n",
       " [('The', 0.0),\n",
       "  ('cats', -10.47793197631836),\n",
       "  ('annoy', -12.409324645996094),\n",
       "  ('s', -5.624114990234375),\n",
       "  ('Tim', -8.530014038085938),\n",
       "  ('.', -2.160125732421875)],\n",
       " [('Rose', 0.0),\n",
       "  ('wasn', -8.536266326904297),\n",
       "  (\"'t\", -0.002288818359375),\n",
       "  ('boasting', -11.13873291015625),\n",
       "  ('Mark', -12.629707336425781)],\n",
       " [('Carl', 0.0),\n",
       "  ('os', -6.095460891723633),\n",
       "  ('said', -5.179496765136719),\n",
       "  ('that', -2.370147705078125),\n",
       "  ('Lori', -12.451545715332031),\n",
       "  ('helped', -7.916389465332031),\n",
       "  ('himself', -7.626190185546875),\n",
       "  ('.', -4.432945251464844)]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.token_score(unacceptable_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c75b1a",
   "metadata": {},
   "source": [
    "## Accuracy of BERT-base-uncased\n",
    "\n",
    "On the same four sentence-pair stimuli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d69df553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model achieves an accuracy of 75.0%\n"
     ]
    }
   ],
   "source": [
    "lm = scorer.MaskedLMScorer('bert-base-uncased', 'cpu') # for GPU use cuda:<DEVICENAME>\n",
    "\n",
    "acceptable_scores = lm.sequence_score(acceptable_sentences, base_two=True)\n",
    "unacceptable_scores = lm.sequence_score(unacceptable_sentences, base_two=True)\n",
    "\n",
    "comparisons = torch.tensor(acceptable_scores) > torch.tensor(unacceptable_scores)\n",
    "\n",
    "comparisons = torch.tensor(acceptable_scores) > torch.tensor(unacceptable_scores)\n",
    "acc = comparisons.float().mean().item()\n",
    "\n",
    "print(f\"The model achieves an accuracy of {round(acc*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a3ec1d",
   "metadata": {},
   "source": [
    "# cwe Module\n",
    "\n",
    "The cwe (pronounced \"sewey\") module allows extraction of token/phrase representations at various layers of any huggingface `transformers` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60beaaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minicons import cwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "73596060",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = cwe.CWE('bert-base-uncased', 'cpu') # for GPU use cuda:<DEVICENAME>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae05d93",
   "metadata": {},
   "source": [
    "## Input representation\n",
    "\n",
    "`cwe` expects inputs to be formatted in the following way:\n",
    "\n",
    "```py\n",
    "[\n",
    "  (sentence_1, word_1),\n",
    "  (sentence_2, word_2),\n",
    "  ....\n",
    "  (sentence_n, word_n)\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a3f43cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli = [\n",
    "    ['This aircraft works by jet propulsion.', 'aircraft'],\n",
    "    ['His passion is making model aircraft.', 'aircraft'],\n",
    "    ['The aircraft was flying in a northerly direction.', 'aircraft'],\n",
    "    ['A small aircraft was obstructing the runway.', 'aircraft'],\n",
    "    ['The aircraft is powered by three jet engines.', 'aircraft']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60820ba",
   "metadata": {},
   "source": [
    "### Extract representations from any layer or a combination of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7c0fe55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1875,  1.3159, -0.5299,  ..., -0.6241,  1.1589,  0.1093],\n",
       "        [ 1.0992,  1.2651, -0.5388,  ..., -0.4278,  1.3408,  0.1456],\n",
       "        [ 0.2353,  1.4479, -0.6632,  ..., -0.1825,  1.3137, -0.1166],\n",
       "        [ 0.5227,  1.0542, -0.6658,  ..., -0.5368,  1.2150, -0.0836],\n",
       "        [ 0.0175,  1.2684, -0.6548,  ..., -0.2252,  1.1569, -0.1668]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.extract_representation(stimuli, layer = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0aad49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.1875,  1.3159, -0.5299,  ..., -0.6241,  1.1589,  0.1093],\n",
       "         [ 1.0992,  1.2651, -0.5388,  ..., -0.4278,  1.3408,  0.1456],\n",
       "         [ 0.2353,  1.4479, -0.6632,  ..., -0.1825,  1.3137, -0.1166],\n",
       "         [ 0.5227,  1.0542, -0.6658,  ..., -0.5368,  1.2150, -0.0836],\n",
       "         [ 0.0175,  1.2684, -0.6548,  ..., -0.2252,  1.1569, -0.1668]]),\n",
       " tensor([[ 1.1305,  1.2379, -0.3605,  ..., -0.2164,  0.7634,  0.2290],\n",
       "         [ 1.5314,  1.1103, -0.3012,  ...,  0.3013,  1.1243, -0.1035],\n",
       "         [ 0.5519,  0.3571,  0.1852,  ..., -0.0317,  0.3467, -0.5793],\n",
       "         [ 0.4403,  0.9158,  0.3346,  ..., -0.6312,  0.7955, -0.0562],\n",
       "         [ 0.2733,  1.0285, -0.3388,  ...,  0.5740,  0.2786, -0.1991]]),\n",
       " tensor([[ 1.0789,  1.2996, -0.3051,  ..., -0.3042,  0.2242,  0.3323],\n",
       "         [ 1.6647,  1.3595,  0.0095,  ...,  0.2924,  1.0470, -0.4102],\n",
       "         [ 0.4315,  0.2476,  0.2358,  ..., -0.4528,  0.4465, -0.5881],\n",
       "         [ 0.4200,  1.0115,  0.6303,  ..., -1.0683,  0.8520, -0.1810],\n",
       "         [ 0.3790,  0.9311, -0.0212,  ...,  0.1781, -0.2400, -0.3695]])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.extract_representation(stimuli, layer = [1,6,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710f7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
