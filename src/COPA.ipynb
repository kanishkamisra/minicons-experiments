{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bbdff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from minicons import scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50a6ed16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "lm = scorer.IncrementalLMScorer('gpt2-xl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3043965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hypothesis(choice):\n",
    "    choice_split = choice.split(\" \")\n",
    "    if choice_split[0] == \"I\":\n",
    "        choice = choice\n",
    "    else:\n",
    "        choice = \" \".join([choice_split[0].lower()] + choice_split[1:])\n",
    "\n",
    "    return choice\n",
    "\n",
    "def create_stimuli(instance):\n",
    "    premise, choice1, choice2, question, label = instance['premise'], instance['choice1'], instance['choice2'], instance['question'], instance['label']\n",
    "\n",
    "    domain = {\n",
    "        'cause': ' because',\n",
    "        'effect': ' so'\n",
    "    }\n",
    "\n",
    "    hypothesis1 = create_hypothesis(choice1)\n",
    "    hypothesis2 = create_hypothesis(choice2)\n",
    "\n",
    "    premise = premise[:-1] + domain[question]\n",
    "\n",
    "    if label == 0:\n",
    "        return premise.lower(), hypothesis1, hypothesis2, domain[question].strip()\n",
    "    else:\n",
    "        return premise.lower(), hypothesis2, hypothesis1, domain[question].strip()\n",
    "    \n",
    "def create_stimuli_flipped(instance):\n",
    "    premise, choice1, choice2, question, label = instance['premise'], instance['choice1'], instance['choice2'], instance['question'], instance['label']\n",
    "\n",
    "    domain = {\n",
    "        'cause': ' so',\n",
    "        'effect': ' because'\n",
    "    }\n",
    "\n",
    "    hypothesis1 = create_hypothesis(choice1).lower()[:-1] + domain[question]\n",
    "    hypothesis2 = create_hypothesis(choice2).lower()[:-1] + domain[question]\n",
    "\n",
    "#     premise = premise[:-1] \n",
    "\n",
    "    if label == 0:\n",
    "        return premise.lower(), hypothesis1, hypothesis2, domain[question].strip()\n",
    "    else:\n",
    "        return premise.lower(), hypothesis2, hypothesis1, domain[question].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06820d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"premise\": \"The man turned on the faucet.\", \"choice1\": \"The toilet filled with water.\", \"choice2\": \"Water flowed from the spout.\", \"question\": \"effect\", \"label\": 1, \"idx\": 0}, {\"premise\": \"The bar closed.\", \"choice1\": \"it was crowded.\", \"choice2\": \"it was 3 AM.\", \"question\": \"cause\", \"label\": 1, \"idx\": 0}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87eee33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli = [create_stimuli(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eed1c525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the man turned on the faucet so',\n",
       "  'water flowed from the spout.',\n",
       "  'the toilet filled with water.',\n",
       "  'so'),\n",
       " ('the bar closed because', 'it was 3 AM.', 'it was crowded.', 'because')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c1aa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.7594,  4.7804]) tensor([12.0711,  8.0356]) tensor([ True, False]) tensor([False, False])\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(stimuli, batch_size=2)\n",
    "\n",
    "for batch in dl:\n",
    "    premise, hypothesis1, hypothesis2, domain = batch\n",
    "    premise, hypothesis1, hypothesis2, domain = [list(x) for x in [premise, hypothesis1, hypothesis2, domain]]\n",
    "\n",
    "    lpcn = torch.tensor(lm.partial_score(premise, hypothesis1, reduction=lambda x: x.sum(0).item()))\n",
    "    lpwn = torch.tensor(lm.partial_score(premise, hypothesis2, reduction=lambda x: x.sum(0).item()))\n",
    "    lpcd = torch.tensor(lm.partial_score(domain, hypothesis1, reduction=lambda x: x.sum(0).item()))\n",
    "    lpwd = torch.tensor(lm.partial_score(domain, hypothesis2, reduction=lambda x: x.sum(0).item()))\n",
    "\n",
    "    print(lpcn - lpcd, lpwn - lpwd, lpcn - lpcd > lpwn - lpwd, lpcn > lpwn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bba2ba6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.8036, 7.4328]) tensor([10.2093,  5.8976]) tensor([False,  True])\n"
     ]
    }
   ],
   "source": [
    "stimuli_flipped = [create_stimuli_flipped(d) for d in data]\n",
    "\n",
    "dl = DataLoader(stimuli_flipped, batch_size=2)\n",
    "\n",
    "for batch in dl:\n",
    "    premise, hypothesis1, hypothesis2, domain = batch\n",
    "    premise, hypothesis1, hypothesis2, domain = [list(x) for x in [premise, hypothesis1, hypothesis2, domain]]\n",
    "\n",
    "    lpcn = torch.tensor(lm.partial_score(hypothesis1, premise, reduction=lambda x: x.sum(0).item()))\n",
    "    lpwn = torch.tensor(lm.partial_score(hypothesis2, premise, reduction=lambda x: x.sum(0).item()))\n",
    "    lpcd = torch.tensor(lm.partial_score(domain, premise, reduction=lambda x: x.sum(0).item()))\n",
    "    lpwd = torch.tensor(lm.partial_score(domain, premise, reduction=lambda x: x.sum(0).item()))\n",
    "\n",
    "    print(lpcn - lpcd, lpwn - lpwd, lpcn - lpcd > lpwn - lpwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0db3cd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpcn > lpwn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "501f787f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-27.7210, -17.2235])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7da69745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpcn > lpwn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5ee96e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('the', 0.0),\n",
       "  ('man', -5.960054397583008),\n",
       "  ('turned', -7.484256744384766),\n",
       "  ('on', -3.765570640563965),\n",
       "  ('the', -1.1261520385742188),\n",
       "  ('f', -4.826846599578857),\n",
       "  ('auc', -0.027098655700683594),\n",
       "  ('et', -0.08421897888183594),\n",
       "  ('so', -5.881808280944824),\n",
       "  ('the', -1.6875057220458984),\n",
       "  ('toilet', -6.178640365600586),\n",
       "  ('filled', -5.008761405944824),\n",
       "  ('with', -0.9246549606323242),\n",
       "  ('water', -0.3520994186401367),\n",
       "  ('.', -1.4982290267944336)],\n",
       " [('the', 0.0),\n",
       "  ('bar', -8.088858604431152),\n",
       "  ('closed', -7.8573174476623535),\n",
       "  ('because', -5.538971900939941),\n",
       "  ('it', -2.4520950317382812),\n",
       "  ('was', -0.4408855438232422),\n",
       "  ('crowded', -4.37636137008667),\n",
       "  ('.', -1.9185810089111328)]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.token_score([f\"{x[0]} {x[1]}\" for x in list(zip(premise, hypothesis2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d033b607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the man turned on the faucet so', 'water flowed from the spout.')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(premise, hypothesis1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8706bf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.823296546936035"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2.4520950317382812 + -0.4408855438232422 + -6.21660041809082 + -3.241485595703125 + -2.4722299575805664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "19529a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('so', 0.0),\n",
       "  ('the', -4.760571479797363),\n",
       "  ('toilet', -9.693585395812988),\n",
       "  ('filled', -8.273508071899414),\n",
       "  ('with', -0.7671117782592773),\n",
       "  ('water', -1.8473739624023438),\n",
       "  ('.', -2.3788585662841797)],\n",
       " [('because', 0.0),\n",
       "  ('it', -2.3379716873168945),\n",
       "  ('was', -2.228343963623047),\n",
       "  ('crowded', -9.716365814208984),\n",
       "  ('.', -2.9408254623413086)]]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.token_score([f\"{x[0]} {x[1]}\" for x in list(zip(domain, hypothesis2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cba91ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19.603700160980225"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2.3379716873168945 + -2.228343963623047 + -8.116579055786133 + -3.3626742362976074 + -3.558131217956543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6eeb18c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-30.6454, -19.6037])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "781603d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.7804036140441895"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-14.823296546936035 - -19.603700160980225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5ca11a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('so', 0.0),\n",
       "  ('water', -10.4304780960083),\n",
       "  ('flowed', -8.087547302246094),\n",
       "  ('from', -2.5472497940063477),\n",
       "  ('the', -0.6567258834838867),\n",
       "  ('sp', -6.336228370666504),\n",
       "  ('out', -0.6313705444335938),\n",
       "  ('.', -1.955796241760254)],\n",
       " [('because', 0.0),\n",
       "  ('it', -2.3379716873168945),\n",
       "  ('was', -2.228343963623047),\n",
       "  ('3', -8.116579055786133),\n",
       "  ('AM', -3.3626742362976074),\n",
       "  ('.', -3.558131217956543)]]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.token_score([f\"{x[0]} {x[1]}\" for x in list(zip(domain, hypothesis1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0520ec33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('water', 0.0),\n",
       "  ('flowed', -11.430306434631348),\n",
       "  ('from', -2.6032838821411133),\n",
       "  ('the', -0.6741828918457031),\n",
       "  ('sp', -6.970684051513672),\n",
       "  ('out', -0.7625389099121094),\n",
       "  ('because', -7.885451793670654),\n",
       "  ('the', -1.1935720443725586),\n",
       "  ('man', -6.702916145324707),\n",
       "  ('turned', -6.2994232177734375),\n",
       "  ('on', -3.005727767944336),\n",
       "  ('the', -0.2837047576904297),\n",
       "  ('f', -2.0682010650634766),\n",
       "  ('auc', -0.0009765625),\n",
       "  ('et', -0.019672393798828125)],\n",
       " [('it', 0.0),\n",
       "  ('was', -4.292654037475586),\n",
       "  ('3', -7.729968070983887),\n",
       "  ('am', -5.6749043464660645),\n",
       "  ('so', -5.807781219482422),\n",
       "  ('the', -3.3985538482666016),\n",
       "  ('bar', -5.1301984786987305),\n",
       "  ('closed', -4.928037643432617)]]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.token_score([f\"{x[0]} {x[1]}\" for x in list(zip(hypothesis1, premise))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d08d43ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('the', 0.0),\n",
       "  ('toilet', -9.90822982788086),\n",
       "  ('filled', -8.217606544494629),\n",
       "  ('with', -0.3010854721069336),\n",
       "  ('water', -2.0568485260009766),\n",
       "  ('because', -6.105167865753174),\n",
       "  ('the', -1.6206865310668945),\n",
       "  ('man', -5.077610492706299),\n",
       "  ('turned', -6.318398475646973),\n",
       "  ('on', -1.8222923278808594),\n",
       "  ('the', -0.17661190032958984),\n",
       "  ('f', -1.5234184265136719),\n",
       "  ('auc', -0.0002613067626953125),\n",
       "  ('et', -0.04168701171875)],\n",
       " [('it', 0.0),\n",
       "  ('was', -4.292654037475586),\n",
       "  ('crowded', -10.155437469482422),\n",
       "  ('so', -5.501846790313721),\n",
       "  ('the', -3.220942497253418),\n",
       "  ('bar', -5.715605735778809),\n",
       "  ('closed', -6.145937919616699)]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.token_score([f\"{x[0]} {x[1]}\" for x in list(zip(hypothesis2, premise))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f67939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
